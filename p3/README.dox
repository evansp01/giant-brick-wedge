/**

@mainpage 15-410 Project 3

@author Jonathan Ong (jonathao)
@author Evan Palmer (esp)


Scheduler
=========

Our scheduler implements a round robin system. We maintain two queues, a
priority queue and a standard queue. Threads which were either suspended or
asleep and are being scheduled by the kernel are added to the priority queue.
Threads which are already running and are being re-scheduled on a timer
interrupt are added to the standard queue.

We want to give priority to threads which are being newly scheduled. Threads
are typically descheduled on a mutex when a critical resource is unavailable.
Giving such threads priority when resuming execution reduces te amount of time
for which the critical resources are left unused. Placing newly scheduled
threads in a FIFO queue ensures that the order of scheduling is maintained.

We guarantee progress of the threads in the standard queue by ensuring that 1
thread from the standard queue runs for every 2 threads that run from the
priority queue. This ensures that there does exist a scenario where threads
in the standard queue are starved by an continuous stream of newly scheduled
threads in the priority queue.


Mutexes / Cvars
===============

Our mutexes and condition variables keep a list of the number of threads
waiting on it, along with the appropriate count of waiting threads. Threads are
descheduled if the mutex is currently locked. Whenever the mutex is unlocked or
the condition variable is signalled, the next thread in the list will be
re-scheduled by the unlocking/signalling thread. Thus our mutexes do not cause
threads to spin in a yield loop.

We ensure that the sections of our mutex and condition variable code which
insert and remove from the list of waiting threads are kept atomic by
disabling interrupts across such sections.
    
We do not use malloc in our implementation of mutexes and condition variables.
Nodes for the linked lists of waiting threads are allocated on the stack.


Virtual Memory
==============

Although we do not allow for page faults in kernel mode, we enabled write
protection, so that we would get an error if the kernel attempted to write
to read only user memory.

The page directory and page tables for each process are allocated in kernel
memory so that during a page fault, processes can examine their page table
structure to determine the cause of the fault. Frames are allocated
from the USER_MEM section of memory.

Unused frames are tracked in an implicit stack with a pointer to the next
unused frame stored in the first word of unused frames. Since pages cannot be
written to or read from without being mapped, in order to allocate or free a
frame, the frame is first mapped to kernel mode where the implicit pointer can
be safely read or written without the risk of an unwanted write from the user.
Then the list is updated, and the frame is either freed or allocated.

Zfod is implemented by defining the firt user mem page to be the zero page.
All zfod page table entries are mapped to this page. If a zfod entry is
writeable, then the zfod bit (the first user available bit) in the page
table is set. When a page fault occurs, the kernel checks if the page to see
if it is mapped to the zfod page, and the zfod bit is set. If the check passes
then a real frame is allocated. Since multipe faults on the same page can
happen concurrently, it is also necessary for the fault handler to check if
the fault wouldn't have happend in the current state (that is, has already
been resolved) and ignore the fault in these cases.

New pages and remove pages are implemented by keeping track of all allocations
made by the user. In a request to new pages, we check all pages associated with
the allocation in the page directory, and if all are unallocated, the
allocation is made. Remove pages simply looks through all allocations made in
the current process, and deletes the requested one. Freeing allocated user
memory when cleaning up a process is as simple as freeing every allocation
made through new pages.

In general, since our kernel allows for multiple threads per process, any
system call which reads or writes to user memory must hold the lock for the
current processes page directory. Since we do not allow page faults in kernel
mode, before writing to kernel memory in addition to checking that it is valid
the kernel must map all zfod pages which will be touched during the write. This
is done using the vm_back function.
    
Preemption
==========

Our kernel disables interrupts during the scheduler, and for short periods of
time in readline, sleep, page directory switching, and in our locking
primitives. Other than these few cases our kernel can recevie interrupts at
all times.

Wait / Vanish
=============

Processes have a lock for their parent pointer and their children list. To
detach a child process from its parent, the parent mutex must be held to remove
the parent pointer from the child, and the children mutex of the parent must be
held to remove the child process from the parent's list of processes.

In all cases in wait/vanish, the parent lock is acquired before the child lock.
This standardization ensures that we avoid deadlock. 


Thread/Process Exit
===================

We free as much memory as possible from the thread/process data structures when
a thread/process exits, so as to minimize the size of the zombie threads and
processes. A thread/process is unable to free its own TCB and kernel page
directory, as that would prevent it from context switching to other threads.

We ensure that the memory for its TCB and kernel page directory is freed
quickly, by doing so whenever a thread acquires the malloc mutex. Since the
malloc mutex is acquired in thread_exit, This ensures that at any point in
time, there is at most one TCB/page directory which is left unfreed. This also
ensures that whenever a call to malloc is made, we are assured that there is
no unfreed memory from zombie threads, since the thread must acquire the malloc
mutex before calling malloc, and the zombie thread memory is freed before
the acquire malloc call returns.

    
Readline
========

Our keyboard interrupt handler converts the input scancodes into characters and
places them in a keyboard buffer. Processing the characters ensure that
backspace characters take immediate effect, and thus we can accurately keep
track of the number of available characters in the buffer. This allows us to
determine if a thread in the readline syscall should immediately retrieve
characters from the buffer, or to deschedule and wait until there are enough
characters or a newline available.

Interrupts are only disabled in the readline function each time a character is
removed from the keyboard buffer, to prevent interleavings of adding and
removing from the buffer. We keep the period of disabled interrupts small to
ensure that readline is largely pre-emptible.

We keep track of the number of processed characters in the keyboard buffer, as
well as the number of newline characters. Each time a readline syscall is made,
a check is performed to see if there is a line available in the buffer (i.e.
either there is a newline character or there are at least enough characters to
fill the length of the user buffer). If there is no available line, then the
calling thread is suspended until one is available, at which point the keyboard
interrupt handler will signal the descheduled readline thread.

We define the readline buffer size to be CONSOLE_WIDTH*(CONSOLE_HEIGHT-1),
i.e. the size of the console screen minus one line. This is to prevent users
from being able to type until characters have scrolled offscreen, as echoed
characters which are scrolled offscreen are no longer kept in console memory.
The 'minus one line' accounts for the cursor being at any possible column
position on the current row. This maximum buffer size would prevent scrolling
even if the cursor was at the last column of the row.

When a call to readline starts, if there are already characters waiting in the
buffer, these characters are echoed before readline returns and before any
other characters are accepted. This ensures that if the user is typing, they
see what will go to readline, and if the characters were already available, it
looks as if they were typed while readline was running.


Sleep
=====

Our sleep function is implemented by adding threads to a sorted linked list. In
order to read from the list, threads must hold a mutex, and in order to modify
the list, interrupts must be disabled.

This allows the sleep syscall to grab sleeper list lock, and search for the
position where the current thread should be added to that list. It can then
disable interrupts and add the thread to the list. Finally when the the thread
is awoken, it removes itsself from the sleeper list after grabbing the lock and
disabling interrupts.

This ensures that even though the sleep syscall takes O(n) time in the number
of sleeping threads, interrupts are only disabled for O(1) time.

The scheduler needs only to check if the first item in the list is still
sleeping and is ready to wake up. This takes O(1) time and does not require
the list lock.


Exec / Fork
===========

In order to simplify our exec and fork implementations we chose not to allow
processes with multiple threads to fork or exec. This means that when a
thread is in fork or exec, it is the only thread in its process which allows
it to hold very few locks througout the call to fork or exec.
    
Exec
====

Our exec implementation makes an effort to protect conventionally read only
sections of the executable in memory, and to allocate the user stack and bss
section as zfod. If either the text section or rodata section does not share
a page with a writeable section, the page will be allocated as read only.
Similarly, if the bss section is on its own page, it will be zfod allocated.

If the user stack is larger than one page, all pages after the first page will
be zfod allocated. The first page is allocated since we expect that every
process will touch its stack almost immediately upon entering user mode since
they all run the autostack handler.

    
Gettid
======

We store the pointer to the kernel thread's control block at the top of its
thread stack. This allows us to look up any TCB variables, including the thread
id, rather quickly in normal circumstances. We access the TCB pointer using a
macro to get the top of the current kernel stack.


Thread States
=============

We define specific thread states to ensure that functions which handle
scheduling/descheduling and sleeping only work on threads which are in the
appropriate state for the function. For instance, kernel descheduled threads
are set to T_KERN_SUSPENDED, while threads which requested to be descheduled by
hthe user are set to T_SUSPENDED. This separation of states ensures that the
user cannot call make_runnable() to reschedule threads which have been
descheduled or put to sleep by the kernel.

Hash Table
==========

In some places we use a hash table. In general we don't want system calls to
fail because the hash table can't resize. Since our hash table is
implemented with separate chaining, if we are supposed to resize, but malloc
fails, we just don't resize. This means that when we run out of memory our
hash table will degenerate to linked list behavior, but it will not fail.


*/
