/**

@mainpage 15-410 Project 2

@author Jonathan Ong (jonathao)
@author Evan Palmer (esp)


Concurrency
==========

Mutexes
=======

Our mutexes are fairly standard. They use an atomic exchange instruction to
acquire the lock, and threads which fail to acquire the lock yield because the
kernel is single threaded.

Our mutexes have a few optimizations over a simple implementation

while(atomic_xchg(mutex->lock, LOCKED) == LOCKED){
    yield(-1);
}

When a thread acquires the lock on a mutex, it sets itself as the owner of that
mutex. When the owner is set, other threads which fail to get to the lock will
yield to the owner instead of to an arbitrary thread. This helps in the case
where many threads are waiting on a single mutex, since once the owner is set
the threads will yield to the thread with the mutex.

Additionally we keep an atomic counter of the number of threads waiting on the
mutex. When threads attempt to lock the mutex, they first optimistically try
to grab the lock, and if that fails, they increment the waiting counter and
enter the yield and try to lock loop.

When a thread releases a mutex, it checks to see if there are currently any
threads waiting. If there are threads waiting on the mutex, the unlocking thread
yields to an arbitrary thread. This prevents a single thread from hogging the
lock in a case where there is code like.

for(;;) {
    mutex_lock(mutex);
    i++;
    mutex_unlock(mutex);
}

We considered implementing locks with an even stronger fairness guarantee
using fetch and add to produce tickets, but it seemed like under heavy contention
these locks would require many calls to yield, since acquiring thread would have
to yield until the thread with the correct ticket got scheduled. Maybe this
could be improved by adding a lock free data structure which recorded who had
what ticket, but that seemed unnecessarily complex.

Our locks have the nice property that in the common case, they are very simple.
If a lock is not contended, acquiring the lock is little more than an exchange
and releasing the lock does not include yielding. It is only under contention
that we use the atomic counters and yield tricks.

Condition Variables
===================

Our condition variable implementation is not very exciting. In cond_wait
we needed to atomically release the condition variable mutex and deschedule
the thread. This operation only needs to be atomic with respect to cond_signal,
so we implement the guarantee there.

In cond_signal, when waking up a thread, we keep in mind that the thread might
not yet have been descheduled. If the schedule system call returns an error,
we yield to the thread we are attempting to schedule, allowing it to deschedule
itself before we attempt again. So, we only conclude that a thread has been
awoken once the schedule system call has been run without an error.

Semaphores
==========
Our semaphores were implemented using mutexes and condition variables. Our
implementation is straightforward and gets its guarantees for fairness from
our implementations of mutexes and condition variables.

Reader Writer Locks
===================
Our reader/writer locks were implemented using condition variables and mutexes.

We prevent the starvation of readers by allowing readers to acquire the lock as
long as there are no writers waiting, and by ensuring that readers which join
the queue ahead of writers will get to go in that order. Whenever one reader
acquires the lock, all readers waiting in line at that point in time will also
acquire the lock to maximize efficiency. If there are writers waiting, new
readers will have to wait for those writers to finish before proceeding.
Readers are guaranteed a finite number of writers to wait for (at most all the
writers in the queue at the point in time the reader joins).

We prevent the starvation of writers by ensuring that whenever a writer joins
the waiting queue and the lock is in read mode, all future readers attempting
to acquire the lock will wait instead of proceeding. Thus the waiting writers
have a finite number of readers to wait on (all readers in the queue at the
point in time when the writer joins) before they are guaranteed to acquire
the lock.

Thread Library
==============

Thread Init
===========

In thread init we allocate grow the main thread's stack to at least the size
specified by the size parameter. If the main thread's stack is already larger
than this size, we do not take any space away. Additionally thread_init
is the location where we inform malloc that it must start using locks, and
do a few other such things.

tid is system tid and why
-------------------------

We chose our thread ids to match the system thread id. There are cases like
an M:N system thread to thread implementation, but it works in our case.
Additionally, using the system id allows us for very simple and efficient
implementations of thr_yield, and greatly simplifies calling schedule and
deschedule in our condition variable code.

Fine grained locks
------------------

Our locking strategy allows for a fair amount of concurrency in the thread
library. We have a single lock for operations which traverse of modify the
tcb list, and then a lock for each tcb entry. As a result, once the thread
library calls get the tcb entry they will be operating on, they do not block
other thread library calls. We generally maintain the invariant that threads
with an entry lock will not attempt to gain the global lock so that we cannot
have circular wait.

Frame Allocator
===============

Our frame allocator keeps track of frames which have been released by exited
threads. These frames are reused to ensure that the memory efficiency is
maximized. This can be done since all thread frames are guaranteed to be of a
standard size. The allocator only requests new frames once there are no
remaining frames in the list of reusable frames.

Thread Create
=============

Storing in registers for create
-------------------------------

Our thread create is written in assembly since once we are in the child thread
we don't want to use the stack until we have set up the stack pointer so we
are not on our parent's stack.

Making sure tcb is created when function returns
------------------------------------------------

Thread create is responsible for adding the entry for the created thread to the
tcb. It is important that when the parent returns, and when the child starts
running this tcb entry exists. To ensure this, the first thread which is run
will create the tcb entry, and then wait on a condition variable for the second
thread to acknowledge that the entry has been created.

Simply checking if the tcb entry exists and creating it if not in both threads
is not sufficient to prevent a race. If the child thread exits and is joined
before the main thread gets to run, this would result in an extra tcb entry
being added for the child.

Thread Exit and Join
====================

Thread exit is responsible for cleaning up the thread stack and placing the
return status in its tcb entry. This ensures that the memory used by the thread
is freed in a timely manner. The tcb entry is retained to allow other threads
to join to the exited thread in the future.

We created an additional field within our tcb to indicate if a thread has
already requested to join the current thread. This ensures that only one
thread can wait to join a particular thread, while other join requests would
immediately fail at the point of request.

Threads must release mutexes before releasing its stack frame and vanishing.
Thus there is a possibly race condition since a stack frame has to be marked as
released before it is fully released. This was solved by having a variable in
the tcb marking the frame's usage status. The code to free the frame and vanish
the task was written in assembly to set the frame status to 'unused' and then
immediately vanish. New threads would avoid reusing the frame before the status
had been set, and once the status is set the thread stack is no longer required
and thus would be safe to reuse.

If a thread attempts to join another thread which is still active, it will
wait on a condition variable. The exiting thread signals this conditional
variable right before it exits, thus allowing the joining thread to proceed
in a timely manner.


Thread get id
=============

As part of thread create, we store the created thread's id at the top of its
thread stack. This allows us to look up the thread id quickly in normal
circumstances. To do this, we look at the current value of esp, and determine
which thread stack it is on, and then return the id at the top of that stack.

In cases where esp does not point to a region associated with a thread stack,
we defer to the gettid system call (this could be the case if a thread was
in an exception handler perhaps). It is reasonable to assume that threads
will not execute on other thread's stacks.


Thread exit and exit override
-----------------------------

We wrote an alternate version of exit which gets linked instead of the
provided exit function. This version of exit calls thread exit if the thread
library has been initialized, and does the normal set_status and vanish if it
has not.

The correctness of this solution does depend on the link order of the program.
With the current Makefile, it works, but it's not as clean as we might like.
A nicer solution would be to user the --wrap exit flag in gcc.

For this to work properly:
    libstdlib.a must be in 410USER_LIBS_LATE
    libthread.a must be in STUDENT_LIBS_EARLY


Autostack Handler
=================
Our autostack handler was written according to the specifications provided.
The handler checks that a page fault occurred, grows the stack by the required
amount, then re-registers the handler.

Our thread-crash handler for multi-threaded applications simply kills all
threads in the current task whenever a crash occurs, to prevent further
undefined behavior from occurring.

*/
